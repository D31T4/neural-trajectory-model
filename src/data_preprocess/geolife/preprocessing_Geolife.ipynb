{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy  as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from abc import ABC, abstractmethod"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_geolife():\n",
    "    data = []\n",
    "    for folder in os.listdir('./Geolife Trajectories 1.3/Geolife Trajectories 1.3/Data'):\n",
    "        user = folder\n",
    "        file_path = f\"./Geolife Trajectories 1.3/Geolife Trajectories 1.3/Data/{user}/Trajectory\"\n",
    "     \n",
    "        for filename in os.listdir(file_path):\n",
    "            record = np.genfromtxt(f'{file_path}/{filename}', delimiter=',',skip_header=6,dtype=None, encoding=None)\n",
    "            for item in record:\n",
    "                data_dict = ({'Latitude': item[0], 'Longitude': item[1], '0': item[2], 'Altitute': item[3], 'Date': item[4], 'Date string': item[5], 'Time': item[6], 'UID' : user})\n",
    "                hour, minute, second = data_dict['Time'].split(':')\n",
    "                minute = round(int(minute), -1)\n",
    "                minute = str('%02d' % minute)\n",
    "                if (minute == '00' or minute == '30') and (hour != prev_hour or minute != prev_minute):\n",
    "                    data.append(data_dict)\n",
    "                prev_hour = hour\n",
    "                prev_minute = minute\n",
    "\n",
    "    df = pd.DataFrame(data, columns=['Latitude', 'Longitude', '0', 'Altitute', 'Date', 'Date string', 'Time', 'UID'])\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_out_ranged(min_range, max_range, df):\n",
    "    day_record_count = []\n",
    "    users = df['UID'].unique()\n",
    "    # check the records for a day\n",
    "    for user in users:\n",
    "        dates = df[df['UID'] == user]['Date string'].unique()\n",
    "        for date in dates:\n",
    "            num_record = len(df[(df['UID'] == user) & (df['Date string'] == date)])\n",
    "            if num_record < min_range or num_record > max_range:\n",
    "                df = df.drop(df[(df['UID'] == user) & (df['Date string'] == date)].index)\n",
    "    df = df.reset_index(drop=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discretize and Interpolate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discretizer(ABC):\n",
    "    '''\n",
    "    abstract interface for discretizing points\n",
    "    '''\n",
    "    \n",
    "    @abstractmethod\n",
    "    def discretize(self, points: np.ndarray) -> np.ndarray:\n",
    "        '''\n",
    "        discretize points\n",
    "        '''\n",
    "        return points\n",
    "    \n",
    "class GridDiscretizer(Discretizer):\n",
    "    '''\n",
    "    discretize by mapping to center of grid containing the point\n",
    "    '''\n",
    "\n",
    "    def __init__(self, xrange, yrange, dim):\n",
    "        self.xrange = xrange\n",
    "        self.yrange = yrange\n",
    "        self.dim = dim\n",
    "\n",
    "        self.window_width = (\n",
    "            (xrange[1] - xrange[0]) / dim[0],\n",
    "            (yrange[1] - yrange[0]) / dim[1]\n",
    "        )\n",
    "\n",
    "        self.intercept = (\n",
    "            xrange[0] + self.window_width[0] / 2,\n",
    "            yrange[0] + self.window_width[1] / 2\n",
    "        )\n",
    "\n",
    "        self.slope = (\n",
    "            (xrange[1] - xrange[0] - self.window_width[0]) / (dim[0] - 1),\n",
    "            (yrange[1] - yrange[0] - self.window_width[1]) / (dim[1] - 1)\n",
    "        )\n",
    "\n",
    "    def discretize(self, points: np.ndarray) -> np.ndarray:\n",
    "        assert np.all((self.xrange[0] <= points[:, 0]) & (points[:, 0] <= self.xrange[1]))\n",
    "        assert np.all((self.yrange[0] <= points[:, 1]) & (points[:, 1] <= self.yrange[1]))\n",
    "\n",
    "        out = np.zeros_like(points, dtype=float)\n",
    "\n",
    "        # out[:, 0] = self.intercept[0] + self.slope[0] * (points[:, 0] // self.window_width[0]).clip(0, self.dim[0] - 1)\n",
    "        # out[:, 1] = self.intercept[1] + self.slope[1] * (points[:, 1] // self.window_width[1]).clip(0, self.dim[1] - 1)\n",
    "\n",
    "        x_indices = ((points[:, 0] - self.xrange[0]) / self.window_width[0])\n",
    "        y_indices = ((points[:, 1] - self.yrange[0]) / self.window_width[1])\n",
    "\n",
    "        # out[:, 0] = self.intercept[0] + self.slope[0] * x_indices.clip(0, self.dim[0] - 1)\n",
    "        # out[:, 1] = self.intercept[1] + self.slope[1] * y_indices.clip(0, self.dim[0] - 1)\n",
    "        out[:, 0] = self.intercept[0] + self.slope[0] * np.round(x_indices)\n",
    "        out[:, 1] = self.intercept[1] + self.slope[1] * np.round(y_indices)\n",
    "        return out\n",
    "    \n",
    "    def points(self):\n",
    "        x = self.xrange[0] + self.slope[0] * np.arange(0, self.dim[0])\n",
    "        y = self.yrange[0] + self.slope[1] * np.arange(0, self.dim[1])\n",
    "        return np.meshgrid(x, y)\n",
    "\n",
    "class NearestNeighborDiscretizer(Discretizer):\n",
    "    '''\n",
    "    discretize by mapping to nearest support\n",
    "    '''\n",
    "\n",
    "    def __init__(self, points: np.ndarray):\n",
    "        self.points = points\n",
    "        self.nn = NearestNeighbors(n_neighbors=1).fit(points)\n",
    "\n",
    "    def discretize(self, points: np.ndarray) -> np.ndarray:\n",
    "        _, indices = self.nn.kneighbors(points)\n",
    "        return self.points[indices[:, 0], :]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpolate(df):\n",
    "    df['datetime'] = (df['Date string'].astype(str) + ' ' + df['Time'].astype(str))\n",
    "    df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "    df['Latitude'] = pd.to_numeric(df['Latitude'])\n",
    "    df['Longitude'] = pd.to_numeric(df['Longitude'])\n",
    "\n",
    "    interpolated_df = pd.DataFrame()\n",
    "    for UID in df['UID'].unique():\n",
    "        for date in df['Date string'].unique():\n",
    "            user_df = df[(df['UID'] == UID) & (df['Date string'] == date)]\n",
    "            \n",
    "            if not user_df.empty:\n",
    "                user_df = user_df.set_index('datetime').resample(rule='1S').interpolate(method='linear')\n",
    "                # print(user_df)\n",
    "                result = user_df.resample(rule='30T', offset=pd.Timedelta(minutes=0, seconds=1)).interpolate(method='linear')\n",
    "                interpolated_df = pd.concat([interpolated_df, result])\n",
    "    return interpolated_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to formatted csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_to_point(time):\n",
    "    hour,min,sec = time.split(':')\n",
    "    hour = int(hour)\n",
    "    loop_hour = 0\n",
    "    loop_min = '00'\n",
    "    count = 0\n",
    "    for _ in range(48):\n",
    "        if (hour == loop_hour) and (min == loop_min):\n",
    "            return count\n",
    "        if loop_min == '30':\n",
    "            loop_hour += 1\n",
    "            loop_min = '00'\n",
    "        else:\n",
    "            loop_min = '30'\n",
    "        count += 1\n",
    "\n",
    "def standardize_output(df):\n",
    "    all_dates = (df['Date string'].unique())\n",
    "    for date in all_dates:\n",
    "        rows_list = []\n",
    "        date_df = df[(df['Date string'] == date)]\n",
    "        all_users_in_date = (date_df['UID'].unique())\n",
    "        if len(all_users_in_date) >= 10:\n",
    "            for user in all_users_in_date:\n",
    "                user_df = date_df[(date_df['UID'] == user)]\n",
    "                uid = int(user)\n",
    "                # start from 0\n",
    "                timepoint = time_to_point(user_df.iloc[0]['Time'])\n",
    "                lat = (user_df.iloc[0]['Latitude'])\n",
    "                long = (user_df.iloc[0]['Longitude'])\n",
    "                for i in range(timepoint):\n",
    "                    time = i\n",
    "                    lat = (user_df.iloc[0]['Latitude'])\n",
    "                    long = (user_df.iloc[0]['Longitude'])\n",
    "                    dict1 = {'uid':uid, 't':i, 'lat':lat, 'long': long}\n",
    "                    rows_list.append(dict1)\n",
    "                # with records\n",
    "                for index, row in user_df.iterrows():\n",
    "                    timepoint = time_to_point(row['Time'])\n",
    "                    lat = (row['Latitude'])\n",
    "                    long = (row['Longitude'])\n",
    "                    dict1 = {'uid':uid, 't':timepoint, 'lat':lat, 'long': long}\n",
    "                    rows_list.append(dict1)\n",
    "                # append to 47\n",
    "                for j in range(timepoint+1, 48):\n",
    "                    time = j\n",
    "                    dict1 = {'uid':uid, 't':j, 'lat':lat, 'long': long}\n",
    "                    rows_list.append(dict1)\n",
    "            \n",
    "            day_df = pd.DataFrame(rows_list)\n",
    "            day_df.to_csv(f'data/{date}.csv', index=False) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main procedures for preprocessing of Geolife data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data reading completed\n",
      "Outliers removed\n",
      "Data Interpolated\n",
      "Data Discretized\n",
      "Data Exported\n"
     ]
    }
   ],
   "source": [
    "# Read data\n",
    "df = read_data_geolife()\n",
    "print('Data reading completed')\n",
    "\n",
    "# Remove outliers\n",
    "beijing_min_longitude, beijing_max_longitude = 115.416827, 117.508251\n",
    "beijing_min_latitude, beijing_max_latitude = 39.442078, 41.058964\n",
    "filtered_df = df[(df['Latitude'] < beijing_max_latitude) & (df['Latitude'] > beijing_min_latitude) & (df['Longitude'] < beijing_max_longitude) & (df['Longitude'] > beijing_min_longitude)]\n",
    "filtered_df = filtered_df.reset_index(drop=True)\n",
    "\n",
    "df = remove_out_ranged(5, 50, filtered_df)\n",
    "print('Outliers removed')\n",
    "df.to_csv(\"checkpoint.csv\")\n",
    "\n",
    "# Interpolate\n",
    "df = pd.read_csv('checkpoint.csv')\n",
    "df = interpolate(df)\n",
    "\n",
    "df['datetime'] = df.index.astype(str)\n",
    "df[['Date string', 'Time']] = df['datetime'].str.split(' ', expand=True)\n",
    "df.dropna(inplace=True)\n",
    "print('Data Interpolated')\n",
    "\n",
    "# Discretize\n",
    "discretizer = GridDiscretizer(xrange=(39.442078, 41.058964), yrange=(115.416827, 117.508251), dim=(100, 100))\n",
    "df[['Latitude', 'Longitude']] = discretizer.discretize(df[['Latitude', 'Longitude']].to_numpy())\n",
    "print('Data Discretized')\n",
    "\n",
    "\n",
    "# Standardize output\n",
    "standardize_output(df) # write to csv.file for further processing\n",
    "print('Data Exported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Unnamed: 0   Latitude   Longitude    0    Altitute  \\\n",
      "datetime                                                                    \n",
      "2008-10-28 01:00:01      0.000000  40.016073  116.305682  0.0  114.000000   \n",
      "2008-10-28 01:30:01      1.108108  40.016073  116.305682  0.0   72.675676   \n",
      "2008-10-28 02:00:01      1.918919  40.016073  116.305682  0.0   70.243243   \n",
      "2008-10-28 02:30:01      3.025475  40.016073  116.305682  0.0  170.395924   \n",
      "2008-10-28 03:00:01      3.216538  40.016073  116.305682  0.0   98.365354   \n",
      "...                           ...        ...         ...  ...         ...   \n",
      "2007-12-11 12:00:01  35490.738658  39.983735  116.326596  0.0  173.622488   \n",
      "2007-12-11 12:30:01  35490.980268  39.983735  116.326596  0.0  161.732195   \n",
      "2007-12-11 13:00:01  35491.944032  39.983735  116.326596  0.0  188.636115   \n",
      "2007-12-11 13:30:01  35492.475818  39.983735  116.305682  0.0  169.994651   \n",
      "2007-12-11 14:00:01  35492.979033  39.999904  116.305682  0.0  148.532069   \n",
      "\n",
      "                             Date Date string      Time    UID  \\\n",
      "datetime                                                         \n",
      "2008-10-28 01:00:01  39749.041678  2008-10-28  01:00:01    0.0   \n",
      "2008-10-28 01:30:01  39749.062512  2008-10-28  01:30:01    0.0   \n",
      "2008-10-28 02:00:01  39749.083345  2008-10-28  02:00:01    0.0   \n",
      "2008-10-28 02:30:01  39749.104178  2008-10-28  02:30:01    0.0   \n",
      "2008-10-28 03:00:01  39749.125012  2008-10-28  03:00:01    0.0   \n",
      "...                           ...         ...       ...    ...   \n",
      "2007-12-11 12:00:01  39427.500012  2007-12-11  12:00:01  181.0   \n",
      "2007-12-11 12:30:01  39427.520845  2007-12-11  12:30:01  181.0   \n",
      "2007-12-11 13:00:01  39427.541678  2007-12-11  13:00:01  181.0   \n",
      "2007-12-11 13:30:01  39427.562512  2007-12-11  13:30:01  181.0   \n",
      "2007-12-11 14:00:01  39427.583345  2007-12-11  14:00:01  181.0   \n",
      "\n",
      "                                datetime  \n",
      "datetime                                  \n",
      "2008-10-28 01:00:01  2008-10-28 01:00:01  \n",
      "2008-10-28 01:30:01  2008-10-28 01:30:01  \n",
      "2008-10-28 02:00:01  2008-10-28 02:00:01  \n",
      "2008-10-28 02:30:01  2008-10-28 02:30:01  \n",
      "2008-10-28 03:00:01  2008-10-28 03:00:01  \n",
      "...                                  ...  \n",
      "2007-12-11 12:00:01  2007-12-11 12:00:01  \n",
      "2007-12-11 12:30:01  2007-12-11 12:30:01  \n",
      "2007-12-11 13:00:01  2007-12-11 13:00:01  \n",
      "2007-12-11 13:30:01  2007-12-11 13:30:01  \n",
      "2007-12-11 14:00:01  2007-12-11 14:00:01  \n",
      "\n",
      "[83025 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
