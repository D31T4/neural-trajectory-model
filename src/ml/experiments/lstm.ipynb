{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import glob\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "from scipy.spatial.distance import cdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_coordinate(latitude, longitude):\n",
    "    global min_lat, max_lat, min_long, max_long\n",
    "    normalized_lat = 2 * (latitude - min_lat) / (max_lat - min_lat) - 1\n",
    "    normalized_long = 2 * (longitude - min_long) / (max_long - min_long) - 1\n",
    "    return normalized_lat, normalized_long\n",
    "\n",
    "def denormalize_coordinate(normalized_lat, normalized_long):\n",
    "    latitude = ((normalized_lat + 1) / 2) * (max_lat - min_lat) + min_lat\n",
    "    longitude = ((normalized_long + 1) / 2) * (max_long - min_long) + min_long\n",
    "    return latitude, longitude\n",
    "\n",
    "def read_data(file):\n",
    "    training = []\n",
    "    df = pd.read_csv(file)\n",
    "    users = df['uid'].unique()\n",
    "    X, y = [], []\n",
    "    for user in users:\n",
    "        new_df = df[(df['uid'] == user)]\n",
    "        LOOKBACK = 3\n",
    "        for i in range(1, 48-LOOKBACK):\n",
    "            feature = [(normalize_coordinate(lat, long)) for lat, long in zip(new_df[i:i + LOOKBACK]['lat'], new_df[i:i + LOOKBACK]['long'])]\n",
    "            target = [(normalize_coordinate(lat, long)) for lat, long in zip(new_df[i + LOOKBACK:i + LOOKBACK + 1]['lat'], new_df[i + LOOKBACK:i + LOOKBACK + 1]['long'])]\n",
    "            X.append(feature)\n",
    "            y.append(target)\n",
    "    \n",
    "    X = np.array([np.array(feature) for feature in X])\n",
    "    y = np.array([np.array(target) for target in y])\n",
    "    return torch.tensor(X, dtype=torch.float64), torch.tensor(y, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_training_data(train_folder):\n",
    "    # training data preparation\n",
    "    outputs = []\n",
    "    for file in glob.glob(train_folder):\n",
    "            outputs.append(read_data(file))\n",
    "    features_list, targets_list = zip(*outputs)\n",
    "    train_features = torch.cat(features_list, dim=0)\n",
    "    train_targets = torch.cat(targets_list, dim=0)\n",
    "    return train_features, train_targets\n",
    "\n",
    "def get_testing_data(test_folder):\n",
    "    # testing data preparation\n",
    "    outputs = []\n",
    "    for file in glob.glob(test_folder):\n",
    "            outputs.append(read_data(file))\n",
    "    features_list, targets_list = zip(*outputs)\n",
    "    test_features = torch.cat(features_list, dim=0)\n",
    "    test_targets = torch.cat(targets_list, dim=0)\n",
    "    return test_features, test_targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving training and testing data for lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameters\n",
    "# Reading data GEOlife\n",
    "beijing_min_longitude, beijing_max_longitude = 115.416827, 117.508251\n",
    "beijing_min_latitude, beijing_max_latitude = 39.442078, 41.058964\n",
    "\n",
    "# Reading data SHANGHAI\n",
    "shanghai_min_longitude = 120.9\n",
    "shanghai_max_longitude = 121.9\n",
    "shanghai_min_latitude = 30.69\n",
    "shanghai_max_latitude = 31.51\n",
    "\n",
    "min_long = beijing_min_longitude\n",
    "max_long = beijing_max_longitude\n",
    "min_lat = beijing_min_latitude\n",
    "max_lat = beijing_max_latitude\n",
    "\n",
    "# Data folder selected from preprocessed data\n",
    "train_folder = './training_data/*'\n",
    "test_folder = './testing_data/*'\n",
    "\n",
    "train_features, train_targets = get_training_data(train_folder)\n",
    "test_features, test_targets = get_testing_data(test_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model definition\n",
    " \n",
    "class TrajModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size=2, hidden_size=40, num_layers=2, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.linear = nn.Linear(40, 2)\n",
    "    def forward(self, x):\n",
    "        x, _ = self.lstm(x.float())\n",
    "        x = self.dropout(x)\n",
    "        x = self.linear(x[:, -1, :])\n",
    "        return x\n",
    "\n",
    "def lstm_training(train_features, train_targets, test_features, test_targets):\n",
    "    model = TrajModel()\n",
    "    optimizer = optim.Adam(model.parameters())\n",
    "    loss_fn = nn.MSELoss()\n",
    "    loader = data.DataLoader(data.TensorDataset(train_features, train_targets), shuffle=True, batch_size=8)\n",
    "    # Data shape = (8, 3, 2), each batch have 8 3-pairs coordinate\n",
    "    n_epochs = 100\n",
    "    for epoch in range(n_epochs):\n",
    "        model.train()\n",
    "        for X_batch, y_batch in loader:\n",
    "            y_pred = model(X_batch).float()\n",
    "            y_pred = torch.unsqueeze(y_pred, 1)\n",
    "            loss = loss_fn(y_pred.float(), y_batch.float())\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # Validation\n",
    "        if epoch % 10 != 0:\n",
    "            continue\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(train_features)\n",
    "            y_pred = torch.unsqueeze(y_pred, 1)\n",
    "            train_rmse = np.sqrt(loss_fn(y_pred, train_targets))\n",
    "            y_pred = model(test_features)\n",
    "            y_pred = torch.unsqueeze(y_pred, 1)\n",
    "            test_rmse = np.sqrt(loss_fn(y_pred, test_targets))\n",
    "        print(\"Epoch %d: train mse %.4f, test mse %.4f\" % (epoch, train_rmse, test_rmse))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: train mse 0.0224, test mse 0.0281\n",
      "Epoch 10: train mse 0.0181, test mse 0.0232\n",
      "Epoch 20: train mse 0.0179, test mse 0.0223\n",
      "Epoch 30: train mse 0.0175, test mse 0.0205\n",
      "Epoch 40: train mse 0.0169, test mse 0.0196\n",
      "Epoch 50: train mse 0.0172, test mse 0.0220\n",
      "Epoch 60: train mse 0.0171, test mse 0.0203\n",
      "Epoch 70: train mse 0.0173, test mse 0.0242\n",
      "Epoch 80: train mse 0.0187, test mse 0.0251\n",
      "Epoch 90: train mse 0.0160, test mse 0.0185\n"
     ]
    }
   ],
   "source": [
    "model = lstm_training(train_features, train_targets, test_features, test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input:\n",
      "tensor([[-0.3098, -0.1296],\n",
      "        [-0.3098, -0.1296],\n",
      "        [-0.3098, -0.1296]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[-0.3063, -0.1265]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[-0.3098, -0.1296]], dtype=torch.float64)\n",
      "-------------\n",
      "Input:\n",
      "tensor([[-0.3621, -0.1273],\n",
      "        [-0.3407, -0.1250],\n",
      "        [-0.3295, -0.1123]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[-0.3226, -0.1092]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[-0.3840, -0.0325]], dtype=torch.float64)\n",
      "-------------\n",
      "Input:\n",
      "tensor([[-0.3287, -0.1486],\n",
      "        [-0.3287, -0.1486],\n",
      "        [-0.3287, -0.1486]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[-0.3174, -0.1481]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[-0.3287, -0.1486]], dtype=torch.float64)\n",
      "-------------\n",
      "Input:\n",
      "tensor([[-0.2221, -0.0453],\n",
      "        [-0.2221, -0.0453],\n",
      "        [-0.2221, -0.0453]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[-0.2335, -0.0814]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[-0.2221, -0.0453]], dtype=torch.float64)\n",
      "-------------\n",
      "Input:\n",
      "tensor([[-0.3635, -0.1042],\n",
      "        [-0.3635, -0.1042],\n",
      "        [-0.3635, -0.1042]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[-0.3648, -0.1017]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[-0.3635, -0.1042]], dtype=torch.float64)\n",
      "-------------\n",
      "Input:\n",
      "tensor([[-0.3585, -0.1278],\n",
      "        [-0.3875, -0.1263],\n",
      "        [-0.3857, -0.1210]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[-0.3721, -0.1146]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[-0.3800, -0.1257]], dtype=torch.float64)\n",
      "-------------\n",
      "Input:\n",
      "tensor([[-0.3507, -0.1547],\n",
      "        [-0.3507, -0.1547],\n",
      "        [-0.3507, -0.1547]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[-0.3508, -0.1541]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[-0.3507, -0.1547]], dtype=torch.float64)\n",
      "-------------\n",
      "Input:\n",
      "tensor([[-0.2754, -0.1108],\n",
      "        [-0.2754, -0.1108],\n",
      "        [-0.2754, -0.1108]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[-0.2508, -0.1077]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[-0.2754, -0.1108]], dtype=torch.float64)\n",
      "-------------\n",
      "Input:\n",
      "tensor([[ 0.2499, -0.4435],\n",
      "        [ 0.2480, -0.4296],\n",
      "        [ 0.2480, -0.4296]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[ 0.3387, -0.5410]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[ 0.2480, -0.4296]], dtype=torch.float64)\n",
      "-------------\n",
      "Input:\n",
      "tensor([[-0.3189, -0.2485],\n",
      "        [-0.3183, -0.2647],\n",
      "        [-0.3197, -0.2648]], dtype=torch.float64)\n",
      "LSTM predicted next coordinates:\n",
      "tensor([[-0.3081, -0.2552]], grad_fn=<AddmmBackward0>)\n",
      "Real output:\n",
      "tensor([[-0.3211, -0.2649]], dtype=torch.float64)\n",
      "-------------\n"
     ]
    }
   ],
   "source": [
    "# Test model performance\n",
    "for i in range(0, 1000, 100):\n",
    "    input = test_features[i]\n",
    "    print(\"Input:\")\n",
    "    print(input)\n",
    "    input = torch.reshape(input, (1, 3, 2))\n",
    "    y = model(input)\n",
    "    print(\"LSTM predicted next coordinates:\")\n",
    "    print(y)\n",
    "    print(\"Real output:\")\n",
    "    print(test_targets[i])\n",
    "    print(\"-------------\")\n",
    "# Save model\n",
    "torch.save(model, 'lstm_model_40_2.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use model for predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from raw data and make predictions using lstm model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_traj(current_traj, next_df):\n",
    "    all_traj = current_traj\n",
    "    if len(current_traj[0]) != 1: \n",
    "        # get the last point to compare and find smallest distance only\n",
    "        current_traj = [[item[-1]] for item in current_traj]\n",
    "    next_points = []\n",
    "    for i in range(len(next_df)):\n",
    "        next_points.append([next_df['lat'][i], next_df['long'][i]])\n",
    "    for index, item in enumerate(current_traj):\n",
    "        distances = cdist(item,next_points)\n",
    "        min_index = np.argmin(distances)\n",
    "        all_traj[index].append(next_points[min_index])\n",
    "        next_points.pop(min_index)\n",
    "    return all_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_traj(csv_file):\n",
    "    # read from data\n",
    "    df = pd.read_csv(csv_file)\n",
    "    time_df = df[(df['t'] == 0)]\n",
    "    time_df.reset_index(drop=True, inplace=True)\n",
    "    # append to 3\n",
    "    all_traj = []\n",
    "    current_traj = []\n",
    "    for i in range(len(time_df)):\n",
    "        current_traj.append([[time_df['lat'][i], time_df['long'][i]]])\n",
    "    time = 1\n",
    "    while len(current_traj[0]) < 3:\n",
    "        next_df = df[(df['t'] == time)]\n",
    "        next_df.reset_index(drop=True, inplace=True)\n",
    "        new_traj = append_traj(current_traj, next_df)\n",
    "        current_traj = new_traj\n",
    "        time += 1\n",
    "    # use model to fill point 3-47\n",
    "    while time < 48:\n",
    "        for index, traj in enumerate(current_traj):\n",
    "            input = [(normalize_coordinate(lat, long)) for lat, long in zip([item[0] for item in traj], [item[1] for item in traj])]\n",
    "            # get the last 3 only\n",
    "            input = input[-3:]\n",
    "            input = torch.tensor(input, dtype=torch.float64)\n",
    "            input = torch.reshape(input, (1, 3, 2))\n",
    "            y = model(input)\n",
    "            x, y = denormalize_coordinate(y[0][0],y[0][1])\n",
    "            new_coor = [x.item(),y.item()]\n",
    "            current_traj[index].append(new_coor)\n",
    "        \n",
    "        next_df = df[(df['t'] == time)]\n",
    "        next_df.reset_index(drop=True, inplace=True)\n",
    "        # get closest point for every current trajectories\n",
    "        current_traj = append_traj(current_traj, next_df)\n",
    "        # remove intermediate point predicted by model\n",
    "        for index, item in enumerate(current_traj):\n",
    "            current_traj[index].pop(-2)\n",
    "        # update time\n",
    "        time += 1\n",
    "    # all final traj with 48 points each\n",
    "    return current_traj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_datafram(df, current_traj):\n",
    "    uid = (df['uid'].unique())\n",
    "    data = []\n",
    "\n",
    "    for index, item in enumerate(current_traj):\n",
    "        t = 0\n",
    "        for time in item:\n",
    "            data.append({'uid': uid[index], 't': t, 'lat': time[0], 'long': time[1]})\n",
    "            t += 1\n",
    "\n",
    "    expected_df = pd.DataFrame(data)\n",
    "    expected_df['t'] = expected_df['t'].astype(int)\n",
    "\n",
    "    expected_df.to_csv('expected.csv', index=False)\n",
    "    df.to_csv('actual.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file = 'testing_data/2009-05-25.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "current_traj = recover_traj(csv_file)\n",
    "export_datafram(df, current_traj)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolov5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
